{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tzlAJD58xbGg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from xclib.data import data_utils\n",
    "import scipy\n",
    "import math  \n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4556,
     "status": "ok",
     "timestamp": 1584748944384,
     "user": {
      "displayName": "Kartik jain",
      "photoUrl": "",
      "userId": "17486299745657913097"
     },
     "user_tz": -330
    },
    "id": "BFoXm4Hw00hn",
    "outputId": "2e0fbdc8-8067-491c-f035-ea47f1290e50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "virus/Adata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kartik/.local/lib/python3.7/site-packages/xclib-0.96-py3.7-linux-x86_64.egg/xclib/data/data_utils.py:173: UserWarning: Header mis-match from inferred shape!\n",
      "  warnings.warn(\"Header mis-match from inferred shape!\")\n"
     ]
    }
   ],
   "source": [
    "path = input()\n",
    "trainX = data_utils.read_sparse_file(path+\"/train_x.txt\").toarray()\n",
    "trainY = np.loadtxt(path+\"/train_y.txt\")\n",
    "testX = data_utils.read_sparse_file(path+\"/test_x.txt\").toarray()\n",
    "testY = np.loadtxt(path+\"/test_y.txt\")\n",
    "valX = data_utils.read_sparse_file(path+\"/valid_x.txt\").toarray()\n",
    "valY = np.loadtxt(path+\"/valid_y.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4cUzkgwf02Gi"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,attr,splitVal,value,n,left,right,parent):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.parent = parent\n",
    "        self.attr = attr\n",
    "        self.splitVal = splitVal\n",
    "        self.majority = value\n",
    "        self.nodeCount = n\n",
    "        \n",
    "class DecisionTree:\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def traverseTree(self,x,node):\n",
    "        if(node.left==None and node.right==None):\n",
    "            return node.majority\n",
    "        if(x[node.attr]<=node.splitVal):\n",
    "            return self.traverseTree(x,node.left)\n",
    "        return self.traverseTree(x,node.right)\n",
    "\n",
    "    def predict(self,dataX):\n",
    "        predictions = []\n",
    "        for i in dataX:\n",
    "            predictions.append(self.traverseTree(i,self.root))\n",
    "        predictions = np.array(predictions)\n",
    "        return predictions\n",
    "\n",
    "    def chooseBestAttr(self,dataX,dataY):\n",
    "        pos = np.sum(dataY==1)\n",
    "        neg = dataY.shape[0]-pos\n",
    "        HY = -(pos/dataY.shape[0])*math.log(pos/dataY.shape[0])-(neg/dataY.shape[0])*math.log(neg/dataY.shape[0])\n",
    "        entropyList=[]\n",
    "        median = np.median(dataX,axis=0)\n",
    "        for i in (range(dataX.shape[1])):\n",
    "            splitVal = median[i]\n",
    "            indices0 = np.where(dataX[:,i] <= splitVal)[0]\n",
    "            indices1 = np.where(dataX[:,i] > splitVal)[0]\n",
    "            if(indices0.shape[0]==0 or indices1.shape[0]==0):\n",
    "                entropyList.append(0)\n",
    "                continue\n",
    "\n",
    "            Y0 = dataY[indices0]\n",
    "            Y1 = dataY[indices1]\n",
    "            pos = np.sum(Y0)\n",
    "            neg = Y0.shape[0]-pos\n",
    "            if(pos==0 or neg==0):\n",
    "                H0=0\n",
    "            else:\n",
    "                H0 = -(pos/Y0.shape[0])*math.log(pos/Y0.shape[0])-(neg/Y0.shape[0])*math.log(neg/Y0.shape[0])\n",
    "            H0 = (indices0.shape[0]/dataX.shape[0])*H0\n",
    "            pos = np.sum(Y1)\n",
    "            neg = Y1.shape[0]-pos\n",
    "            if(pos==0 or neg==0):\n",
    "                H1=0\n",
    "            else:\n",
    "                H1 = -(pos/Y1.shape[0])*math.log(pos/Y1.shape[0])-(neg/Y1.shape[0])*math.log(neg/Y1.shape[0])\n",
    "            H1 = (indices1.shape[0]/dataX.shape[0])*H1\n",
    "            entropyList.append(HY-H0-H1)\n",
    "        if(sum(entropyList)==0):\n",
    "            attr = entropyList.index(max(entropyList))\n",
    "            splitVal = median[i]\n",
    "            indices0 = np.where(dataX[:,i] <= splitVal)[0]\n",
    "            indices1 = np.where(dataX[:,i] > splitVal)[0]\n",
    "            if indices0.shape[0]==0 or indices1.shape[0]==0:\n",
    "                return -1\n",
    "        return entropyList.index(max(entropyList))\n",
    "    \n",
    "    def growTree(self,dataX,dataY,testX,testY,valX,valY,interval):\n",
    "        queue = [(self.root,dataX,dataY,testX,testY,valX,valY)]\n",
    "        count = 0\n",
    "        tTrain,tTest,tVal = dataY.shape[0],testY.shape[0],valY.shape[0]\n",
    "        if(self.root.majority==1):\n",
    "            cTrain,cTest,cVal = np.sum(dataY),np.sum(testY),np.sum(valY)\n",
    "        else:\n",
    "            cTrain,cTest,cVal = np.sum(1-dataY),np.sum(1-testY),np.sum(1-valY)\n",
    "        # nodeCount,trainList,testList,valList = [1],[cTrain/tTrain],[cTest/tTest],[cVal/tVal]\n",
    "        nodeCount,trainList,testList,valList = [],[],[],[]\n",
    "        while(len(queue)!=0):\n",
    "            c = (queue[-1])[0].nodeCount\n",
    "            x,DX,DY,TX,TY,VX,VY = queue.pop(0)\n",
    "            s = np.sum(DY)\n",
    "            if(s == DY.shape[0]):\n",
    "                continue\n",
    "            if(s == 0):\n",
    "                continue\n",
    "            attr = self.chooseBestAttr(DX,DY)\n",
    "            if(attr == -1):\n",
    "                continue   \n",
    "            if(s > DY.shape[0]/2):\n",
    "                val=1\n",
    "                cTrain = cTrain - np.sum(DY)\n",
    "                cTest = cTest - np.sum(TY)\n",
    "                cVal = cVal - np.sum(VY)\n",
    "            else:\n",
    "                val=0\n",
    "                cTrain = cTrain - np.sum(1-DY)\n",
    "                cTest = cTest - np.sum(1-TY)\n",
    "                cVal = cVal - np.sum(1-VY)\n",
    "\n",
    "            seq = DX[:,attr]\n",
    "            splitVal = np.median(seq)\n",
    "            indices0 = np.where(DX[:,attr] <= splitVal)[0]\n",
    "            indices1 = np.where(DX[:,attr] > splitVal)[0]\n",
    "            D0,Y0 = DX[indices0,:],DY[indices0]\n",
    "            D1,Y1 = DX[indices1,:],DY[indices1]\n",
    "\n",
    "            indices0 = np.where(TX[:,attr] <= splitVal)[0]\n",
    "            indices1 = np.where(TX[:,attr] > splitVal)[0]\n",
    "            TX0,TY0 = TX[indices0,:],TY[indices0]\n",
    "            TX1,TY1 = TX[indices1,:],TY[indices1]\n",
    "\n",
    "            indices0 = np.where(VX[:,attr] <= splitVal)[0]\n",
    "            indices1 = np.where(VX[:,attr] > splitVal)[0]\n",
    "            VX0,VY0 = VX[indices0,:],VY[indices0]\n",
    "            VX1,VY1 = VX[indices1,:],VY[indices1]\n",
    "\n",
    "            x.attr,x.splitVal,x.majority = attr,splitVal,val\n",
    "\n",
    "            s = np.sum(Y0)\n",
    "            if(s > Y0.shape[0]/2):\n",
    "                v = 1\n",
    "                cTrain = cTrain + np.sum(Y0)\n",
    "                cTest = cTest + np.sum(TY0)\n",
    "                cVal = cVal + np.sum(VY0)\n",
    "            else:\n",
    "                v = 0\n",
    "                cTrain = cTrain + np.sum(1-Y0)\n",
    "                cTest = cTest + np.sum(1-TY0)\n",
    "                cVal = cVal + np.sum(1-VY0)\n",
    "            left = Node(-1,-1,v,c+1,None,None,x)\n",
    "\n",
    "            s = np.sum(Y1)\n",
    "            if(s > Y1.shape[0]/2):\n",
    "                v = 1\n",
    "                cTrain = cTrain + np.sum(Y1)\n",
    "                cTest = cTest + np.sum(TY1)\n",
    "                cVal = cVal + np.sum(VY1)\n",
    "            else:\n",
    "                v = 0\n",
    "                cTrain = cTrain + np.sum(1-Y1)\n",
    "                cTest = cTest + np.sum(1-TY1)\n",
    "                cVal = cVal + np.sum(1-VY1)\n",
    "            right = Node(-1,-1,v,c+2,None,None,x)\n",
    "\n",
    "            x.left,x.right = left,right\n",
    "            queue.append((left,D0,Y0,TX0,TY0,VX0,VY0))\n",
    "            queue.append((right,D1,Y1,TX1,TY1,VX1,VY1))\n",
    "            count+=1\n",
    "\n",
    "            if(count%interval==0):\n",
    "                nodeCount.append(c+2)\n",
    "                trainList.append(cTrain/tTrain)\n",
    "                testList.append(cTest/tTest)\n",
    "                valList.append(cVal/tVal)\n",
    "        return nodeCount,trainList,testList,valList\n",
    "\n",
    "    def fit(self,trainX,trainY,testX,testY,valX,valY,interval):\n",
    "        s = np.sum(trainY)\n",
    "        if(s > trainY.shape[0]/2):\n",
    "            v = 1\n",
    "        else:\n",
    "            v = 0\n",
    "        self.root = Node(-1,-1,v,0,None,None,None)\n",
    "        nodeCount,trainList,testList,valList = self.growTree(trainX,trainY,testX,testY,valX,valY,interval)\n",
    "        return nodeCount,trainList,testList,valList\n",
    "\n",
    "    def findDepth(self,root):\n",
    "        if(root==None):\n",
    "            return 0\n",
    "        return max(self.findDepth(root.left),self.findDepth(root.right))+1\n",
    "    \n",
    "    def countNodes(self,root):\n",
    "        if(root==None):\n",
    "            return 0\n",
    "        l = self.countNodes(root.left)\n",
    "        r = self.countNodes(root.right)\n",
    "        return l+r+1\n",
    "    \n",
    "    def score(self,pred,dataY):\n",
    "        check = (pred==dataY)\n",
    "        return np.sum(check)/dataY.shape[0]\n",
    "\n",
    "    def checkBinary(self,root):\n",
    "        if(root.left==None and root.right==None):\n",
    "            return 1\n",
    "        if(root.left!=None and root.right==None):\n",
    "            return 0\n",
    "        if(root.left==None and root.right!=None):\n",
    "            return 0\n",
    "\n",
    "        return self.checkBinary(root.left) and self.checkBinary(root.right)\n",
    "\n",
    "    def countLeaves(self,root):\n",
    "        if(root.left==None and root.right==None):\n",
    "            return 1\n",
    "        return self.countLeaves(root.left)+self.countLeaves(root.right)\n",
    "    \n",
    "    def findNodes(self,Xtrain,Ytrain,Xtest,Ytest,Xval,Yval):\n",
    "        queue = [(self.root,Xtrain,Ytrain,Xtest,Ytest,Xval,Yval)]\n",
    "        nodeList,leafList = {},{}\n",
    "        while(len(queue)!=0):\n",
    "            x,trainX,trainY,testX,testY,valX,valY = queue.pop(0)\n",
    "            attr = x.attr\n",
    "            splitVal = x.splitVal\n",
    "            nodeList[x.nodeCount] = (x,trainX,trainY,testX,testY,valX,valY)\n",
    "\n",
    "            if(x.left==None and x.right==None):\n",
    "                leafList[x.nodeCount] = (x,trainX,trainY,testX,testY,valX,valY)\n",
    "                continue\n",
    "            \n",
    "            indices0 = np.where(trainX[:,attr] <= splitVal)[0]\n",
    "            indices1 = np.where(trainX[:,attr] > splitVal)[0]\n",
    "            trainX0,trainY0 = trainX[indices0,:],trainY[indices0]\n",
    "            trainX1,trainY1 = trainX[indices1,:],trainY[indices1]\n",
    "\n",
    "            indices0 = np.where(testX[:,attr] <= splitVal)[0]\n",
    "            indices1 = np.where(testX[:,attr] > splitVal)[0]\n",
    "            testX0,testY0 = testX[indices0,:],testY[indices0]\n",
    "            testX1,testY1 = testX[indices1,:],testY[indices1]\n",
    "\n",
    "            indices0 = np.where(valX[:,attr] <= splitVal)[0]\n",
    "            indices1 = np.where(valX[:,attr] > splitVal)[0]\n",
    "            valX0,valY0 = valX[indices0,:],valY[indices0]\n",
    "            valX1,valY1 = valX[indices1,:],valY[indices1]\n",
    "\n",
    "            queue.append((x.left,trainX0,trainY0,testX0,testY0,valX0,valY0))\n",
    "            queue.append((x.right,trainX1,trainY1,testX1,testY1,valX1,valY1))\n",
    "        return nodeList,leafList\n",
    "\n",
    "    def checkLeaf(self,root,number):\n",
    "        if(root.nodeCount == number):\n",
    "            if(root.left==None and root.right==None):\n",
    "                return 1\n",
    "            return 0\n",
    "        if(root.left==None and root.right==None):\n",
    "            return 1\n",
    "        return self.checkLeaf(root.left,number) and self.checkLeaf(root.right,number)\n",
    "\n",
    "    def pruneNodes(self,root,nodeList,total,cTrain,cTest,cVal,accList,trainTotal,testTotal,valTotal):\n",
    "        if(root.left==None and root.right==None):\n",
    "            if(root.majority == 1):\n",
    "                correctVal = np.sum(nodeList[root.nodeCount][6])\n",
    "                correctTest = np.sum(nodeList[root.nodeCount][4])\n",
    "                correctTrain = np.sum(nodeList[root.nodeCount][2])\n",
    "            else:\n",
    "                correctVal = np.sum(1-nodeList[root.nodeCount][6])\n",
    "                correctTest = np.sum(1-nodeList[root.nodeCount][4])\n",
    "                correctTrain = np.sum(1-nodeList[root.nodeCount][2])\n",
    "            return 1,correctVal,correctTest,correctTrain,accList,cTrain,cTest,cVal,total\n",
    "        \n",
    "        leftNodeCount,cLVal,cLTest,cLTrain,accList,cTrain,cTest,cVal,total = self.pruneNodes(root.left,nodeList,total,cTrain,cTest,cVal,accList,trainTotal,testTotal,valTotal)\n",
    "        rightNodeCount,cRVal,cRTest,cRTrain,accList,cTrain,cTest,cVal,total = self.pruneNodes(root.right,nodeList,total,cTrain,cTest,cVal,accList,trainTotal,testTotal,valTotal)\n",
    "\n",
    "        if(root.majority == 1):\n",
    "            cPVal = np.sum(nodeList[root.nodeCount][6])\n",
    "            cPTest = np.sum(nodeList[root.nodeCount][4])\n",
    "            cPTrain = np.sum(nodeList[root.nodeCount][2])\n",
    "        else:\n",
    "            cPVal = np.sum(1-nodeList[root.nodeCount][6])\n",
    "            cPTest = np.sum(1-nodeList[root.nodeCount][4])\n",
    "            cPTrain = np.sum(1-nodeList[root.nodeCount][2])\n",
    "\n",
    "        rootNodeCount=leftNodeCount+rightNodeCount+1\n",
    "        if(cPVal >= cLVal+cRVal):\n",
    "            cTrain = cTrain - cLTrain - cRTrain + cPTrain\n",
    "            cTest = cTest - cLTest - cRTest + cPTest\n",
    "            cVal = cVal - cLVal - cRVal + cPVal\n",
    "            total = total - leftNodeCount - rightNodeCount\n",
    "\n",
    "            accList.append([total,cTrain/trainTotal,cTest/testTotal,cVal/valTotal])\n",
    "            root.left,root.right=None,None\n",
    "            root.attr,root.splitVal=-1,-1\n",
    "            rootNodeCount=1\n",
    "            return rootNodeCount,cPVal,cPTest,cPTrain,accList,cTrain,cTest,cVal,total\n",
    "\n",
    "        return rootNodeCount,cLVal+cRVal,cLTest+cRTest,cLTrain+cRTrain,accList,cTrain,cTest,cVal,total\n",
    "\n",
    "\n",
    "    def prune(self,trainX,trainY,testX,testY,valX,valY):\n",
    "        nodeList,leafList = self.findNodes(trainX,trainY,testX,testY,valX,valY)\n",
    "        total = self.countNodes(self.root)\n",
    "        correctTrain,correctTest,correctVal = 0,0,0\n",
    "        for i in list(leafList.keys()):\n",
    "            if(leafList[i][0].majority==1):\n",
    "                correctTrain+= np.sum(leafList[i][2])\n",
    "                correctTest+= np.sum(leafList[i][4])\n",
    "                correctVal+= np.sum(leafList[i][6])\n",
    "            else:\n",
    "                correctTrain+= np.sum(1-leafList[i][2])\n",
    "                correctTest+= np.sum(1-leafList[i][4])\n",
    "                correctVal+= np.sum(1-leafList[i][6])\n",
    "        accList = [[total,correctTrain/trainX.shape[0],correctTest/testX.shape[0],correctVal/valX.shape[0]]]\n",
    "        self.pruneNodes(self.root,nodeList,total,correctTrain,correctTest,correctVal,accList,trainX.shape[0],testX.shape[0],valX.shape[0])\n",
    "        return accList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTreeAccuracies(x,train,test,val,title,leg):\n",
    "    y = np.array(train)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    ax = plt.gca()\n",
    "    ax.plot(x,y,label=\"Train Set Accuracies\")\n",
    "    y = np.array(test)\n",
    "    ax.plot(x,y,label=\"Test Set Accuracies\")\n",
    "    y = np.array(val)\n",
    "    ax.plot(x,y,label=\"Validation Set Accuracies\")\n",
    "    plt.title(title)\n",
    "    ax.set_xlabel(\"Node Count\",fontsize=12)\n",
    "    ax.set_ylabel(\"Accuracies\",fontsize=12)\n",
    "    plt.legend(loc=leg)\n",
    "    plt.show()\n",
    "    \n",
    "def oobScore(params,data):\n",
    "    rf = RandomForestClassifier(criterion='entropy',n_estimators=params[0],min_samples_split=params[1],max_features=params[2],oob_score=True,n_jobs=-1)\n",
    "    rf.fit(data[0],data[1])\n",
    "    return (params,rf.oob_score_)\n",
    "    \n",
    "def scorer(clf,X,y):\n",
    "    return clf.oob_score_\n",
    "\n",
    "def findAcc(params,data):\n",
    "    rf = RandomForestClassifier(criterion='entropy',n_estimators=params[0],min_samples_split=params[1],max_features=params[2],oob_score=True,n_jobs=-1)\n",
    "    rf.fit(data[0],data[1])\n",
    "    return (rf.score(data[0],data[1]),rf.score(data[2],data[3]),rf.score(data[4],data[5]))\n",
    "\n",
    "def paramSensitivity(estimatorList,minSamplesList,maxFeaturesList):\n",
    "    n_estimators_varied,min_samples_split_varied,max_features_varied = [],[],[]\n",
    "    data = (trainX,trainY,testX,testY,valX,valY)\n",
    "    for i in estimatorList:\n",
    "        n_estimators_varied.append(findAcc((i,best_min_samples_split,best_max_features),data))\n",
    "    print(\"estimators\",n_estimators_varied)\n",
    "\n",
    "    for i in minSamplesList:\n",
    "        min_samples_split_varied.append(findAcc((best_n_estimators,i,best_max_features),data))\n",
    "    print(\"min samples split\",min_samples_split_varied)\n",
    "\n",
    "\n",
    "    for i in maxFeaturesList:\n",
    "        max_features_varied.append(findAcc((best_n_estimators,best_min_samples_split,i),data))\n",
    "    print(\"max features\",max_features_varied)\n",
    "\n",
    "    return n_estimators_varied,min_samples_split_varied,max_features_varied\n",
    "\n",
    "def plotForest(x,y,title,xlabel,leg): \n",
    "    y = np.array(y) \n",
    "    plt.figure(figsize=(8,6)) \n",
    "    ax = plt.gca()\n",
    "\n",
    "    # ax.plot(x,y[:,0],label=\"Train Set Accuracies\")\n",
    "    ax.plot(x,y[:,1],label=\"Test Set Accuracies\")\n",
    "    ax.plot(x,y[:,2],label=\"Validation Set Accuracies\")\n",
    "    plt.title(title)\n",
    "    ax.set_xlabel(xlabel,fontsize=12)\n",
    "    ax.set_ylabel(\"Accuracies\",fontsize=12)\n",
    "    plt.legend(loc=leg)\n",
    "    plt.savefig(\"/content/drive/My Drive/ML/\"+title+\".jpg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QeNa172VYTtr"
   },
   "source": [
    "## PART A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 62378,
     "status": "ok",
     "timestamp": 1584749180529,
     "user": {
      "displayName": "Kartik jain",
      "photoUrl": "",
      "userId": "17486299745657913097"
     },
     "user_tz": -330
    },
    "id": "GuEOvREZ1Fd1",
    "outputId": "cbf33f09-62e4-49a9-c90f-bf802d4cc773"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31714963912963867\n"
     ]
    }
   ],
   "source": [
    "interval = 10\n",
    "clf = DecisionTree()\n",
    "try:\n",
    "    st = time()\n",
    "    pickle_in = open(\"Tree.pickle\",\"rb\")\n",
    "    clf,nodeCount,trainList,testList,valList = pickle.load(pickle_in)\n",
    "    print(time()-st)\n",
    "except:\n",
    "    st = time()\n",
    "    nodeCount,trainList,testList,valList = clf.fit(trainX,trainY,testX,testY,valX,valY,interval)\n",
    "    print(time()-st)\n",
    "    with open(\"Tree.pickle\", \"wb\") as f:\n",
    "        pickle.dump((clf,nodeCount,trainList,testList,valList), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 61629,
     "status": "ok",
     "timestamp": 1584749181634,
     "user": {
      "displayName": "Kartik jain",
      "photoUrl": "",
      "userId": "17486299745657913097"
     },
     "user_tz": -330
    },
    "id": "gtem7Oz5ZCGa",
    "outputId": "a45e0f72-285f-4cf1-a872-b3d2a51d16e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9047023009287161\n",
      "0.7797505910713458\n",
      "0.775913220841832\n"
     ]
    }
   ],
   "source": [
    "predTrain = clf.predict(trainX)\n",
    "trainScore = clf.score(predTrain,trainY)\n",
    "print(trainScore)\n",
    "predTest = clf.predict(testX)\n",
    "testScore = clf.score(predTest,testY)\n",
    "print(testScore)\n",
    "predVal = clf.predict(valX)\n",
    "valScore = clf.score(predVal,valY)\n",
    "print(valScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 59296,
     "status": "ok",
     "timestamp": 1584749181638,
     "user": {
      "displayName": "Kartik jain",
      "photoUrl": "",
      "userId": "17486299745657913097"
     },
     "user_tz": -330
    },
    "id": "_fE8VVHJY2tZ",
    "outputId": "1a7ce329-30da-4569-8653-15f3965d2180"
   },
   "outputs": [],
   "source": [
    "plotTreeAccuracies(nodeCount,trainList,testList,valList,\"Accuracy vs Number of Nodes\",\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ZlfBj6cY39k"
   },
   "source": [
    "## PART B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 60156,
     "status": "ok",
     "timestamp": 1584749184439,
     "user": {
      "displayName": "Kartik jain",
      "photoUrl": "",
      "userId": "17486299745657913097"
     },
     "user_tz": -330
    },
    "id": "3qQaZrenNuxu",
    "outputId": "79576c16-1dca-403e-f9b5-bff0d7122ea6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.322169542312622\n"
     ]
    }
   ],
   "source": [
    "st = time()\n",
    "accList = clf.prune(trainX,trainY,testX,testY,valX,valY)\n",
    "print(time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57579,
     "status": "ok",
     "timestamp": 1584749185669,
     "user": {
      "displayName": "Kartik jain",
      "photoUrl": "",
      "userId": "17486299745657913097"
     },
     "user_tz": -330
    },
    "id": "4mejxiQaaAD3",
    "outputId": "dc6d541b-e666-4b1c-db50-27d07f463113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8321202849504736\n",
      "0.7976449863242316\n",
      "0.8245874281475988\n"
     ]
    }
   ],
   "source": [
    "predTrain = clf.predict(trainX)\n",
    "trainScore = clf.score(predTrain,trainY)\n",
    "print(trainScore)\n",
    "predTest = clf.predict(testX)\n",
    "testScore = clf.score(predTest,testY)\n",
    "print(testScore)\n",
    "predVal = clf.predict(valX)\n",
    "valScore = clf.score(predVal,valY)\n",
    "print(valScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 55545,
     "status": "ok",
     "timestamp": 1584749185671,
     "user": {
      "displayName": "Kartik jain",
      "photoUrl": "",
      "userId": "17486299745657913097"
     },
     "user_tz": -330
    },
    "id": "3jkQlUChw-e8",
    "outputId": "8adbf2b3-0989-4731-9495-a1d5156abd4b"
   },
   "outputs": [],
   "source": [
    "accList = np.array(accList)\n",
    "plotTreeAccuracies(accList[:,0],accList[:,1],accList[:,2],accList[:,3],\"Accuracy vs Pruned number of Nodes\",\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3owyXCx_aBgP"
   },
   "source": [
    "## PART C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.053854942321777344\n"
     ]
    }
   ],
   "source": [
    "estimatorList = [50,150,250,350,450]\n",
    "minSamplesList = [2,4,6,8,10]\n",
    "maxFeaturesList = [0.1,0.3,0.5,0.7,0.9,1]\n",
    "\n",
    "paraList = list(itertools.product(estimatorList,minSamplesList,maxFeaturesList))\n",
    "data = (trainX,trainY)\n",
    "\n",
    "try:\n",
    "    st = time()\n",
    "    pickle_in = open(\"gridSearch.pickle\",\"rb\")\n",
    "    oobList = pickle.load(pickle_in)\n",
    "    print(time()-st)\n",
    "except:\n",
    "    st = time()\n",
    "    oobList = Parallel(n_jobs=-1)(delayed(oobScore)(i,data) for i in paraList)\n",
    "    print(time()-st)\n",
    "    with open(\"gridSearch.pickle\",\"wb\") as f:\n",
    "        pickle.dump(oobList, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 10, 0.1)\n"
     ]
    }
   ],
   "source": [
    "oobList = np.array(oobList)\n",
    "index = np.where(oobList[:,1]==max(oobList[:,1]))[0][0]\n",
    "print(oobList[index][0])\n",
    "best_max_features = oobList[index][0][2]\n",
    "best_min_samples_split = oobList[index][0][1]\n",
    "best_n_estimators = oobList[index][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vZ4ZLwiraRs3"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy',oob_score=True,n_jobs=-1)\n",
    "parameters = {'n_estimators':[50,150,250,350,450],'max_features':[0.1,0.3,0.5,0.7,0.9,1],'min_samples_split':[2,4,6,8,10]}\n",
    "gridSearchclf = GridSearchCV(rf, parameters,n_jobs=-1,scoring=scorer,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53143,
     "status": "ok",
     "timestamp": 1584749187337,
     "user": {
      "displayName": "Kartik jain",
      "photoUrl": "",
      "userId": "17486299745657913097"
     },
     "user_tz": -330
    },
    "id": "iEqvBgLRadKs",
    "outputId": "476a0aee-34ae-424d-da26-a643da75dd99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kartik/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22.2.post1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/kartik/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.22.2.post1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.19654107093811\n",
      "{'max_features': 0.1, 'min_samples_split': 10, 'n_estimators': 450}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kartik/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator GridSearchCV from version 0.22.2.post1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "9342.362\n",
    "try:\n",
    "    st = time()\n",
    "    pickle_in = open(\"gridCV3.pickle\",\"rb\")\n",
    "    gridSearchclf = pickle.load(pickle_in)\n",
    "    print(time()-st)\n",
    "except:\n",
    "    st = time()\n",
    "    gridSearchclf.fit(trainX,trainY)\n",
    "    print(time()-st)\n",
    "    with open(\"gridCV3.pickle\",\"wb\") as f:\n",
    "        pickle.dump(gridSearchclf, f)\n",
    "print(gridSearchclf.best_params_)\n",
    "best_max_features = gridSearchclf.best_params_['max_features']\n",
    "best_min_samples_split = gridSearchclf.best_params_['min_samples_split']\n",
    "best_n_estimators = gridSearchclf.best_params_['n_estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1385,
     "status": "ok",
     "timestamp": 1584749188768,
     "user": {
      "displayName": "Kartik jain",
      "photoUrl": "",
      "userId": "17486299745657913097"
     },
     "user_tz": -330
    },
    "id": "ZC14I_UraehY",
    "outputId": "038d2af8-5c61-4a4d-a807-d3f75ac2477c"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy',n_estimators=best_n_estimators,max_features=best_max_features,min_samples_split=best_min_samples_split,oob_score=True,n_jobs=-1)\n",
    "st = time()\n",
    "rf.fit(trainX,trainY)\n",
    "print(\"Time\",time()-st)\n",
    "print(rf.oob_score_)\n",
    "print(rf.score(trainX,trainY))\n",
    "print(rf.score(testX,testY))\n",
    "print(rf.score(valX,valY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OwyddIcBbLBi"
   },
   "source": [
    "## PART D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20418,
     "status": "ok",
     "timestamp": 1584749207866,
     "user": {
      "displayName": "Kartik jain",
      "photoUrl": "",
      "userId": "17486299745657913097"
     },
     "user_tz": -330
    },
    "id": "E9R61ycYanzd",
    "outputId": "9a07c5d4-0a28-467b-b56d-d19b84813ef6"
   },
   "outputs": [],
   "source": [
    "estimatorList = [50,150,250,350,450]\n",
    "minSamplesList = [2,4,6,8,10]\n",
    "maxFeaturesList = [0.1,0.3,0.5,0.7,0.9,1]\n",
    "try:\n",
    "    st = time()\n",
    "    pickle_in = open(\"/content/drive/My Drive/ML/paramSensitivity.pickle\",\"rb\")\n",
    "    n_estimators_varied,min_samples_split_varied,max_features_varied = pickle.load(pickle_in)\n",
    "    print(time()-st)\n",
    "except:\n",
    "    st = time()\n",
    "    n_estimators_varied,min_samples_split_varied,max_features_varied = paramSensitivity(estimatorList,minSamplesList,maxFeaturesList)  \n",
    "    print(time()-st)\n",
    "    with open(\"/content/drive/My Drive/ML/paramSensitivity.pickle\",\"wb\") as f:\n",
    "        pickle.dump((n_estimators_varied,min_samples_split_varied,max_features_varied), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2520,
     "status": "ok",
     "timestamp": 1584749210440,
     "user": {
      "displayName": "Kartik jain",
      "photoUrl": "",
      "userId": "17486299745657913097"
     },
     "user_tz": -330
    },
    "id": "pRwuiI_Mas0J",
    "outputId": "f76d08a4-79c6-41b9-a85b-6cb5e8df12c6"
   },
   "outputs": [],
   "source": [
    "plotForest(estimatorList,n_estimators_varied,\"Varying n_estimators\",\"n_estimator\",\"lower right\") \n",
    "plotForest(minSamplesList,min_samples_split_varied,\"Varying min_samples_split\",\"min_samples_split\",\"lower right\") \n",
    "plotForest(maxFeaturesList,max_features_varied,\"Varying max_features\",\"max_features\",\"lower left\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "A3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
